{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad02280a-b8a9-493c-a3e3-8bff19ab86b9",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "## 4. Advanced Implementation with Libraries\n",
    "\n",
    "Now let's explore more sophisticated NER approaches using modern libraries like spaCy and NLTK. We'll compare different methods and analyze their strengths and weaknesses for financial text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d96747-c240-406e-a98b-e9f1a26c2659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .entity-PERSON { background: #ffccd5; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-ORG { background: #c3eeff; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-GPE { background: #c1ffba; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-LOC { background: #d6ffba; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-MONEY { background: #ffe5a8; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-TIME { background: #e5ceff; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-DATE { background: #cecdff; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-PERCENT { background: #bbffee; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-CARDINAL { background: #eeedff; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-TICKER { background: #ffbadd; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-COMPANY { background: #c3eeff; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-PRODUCT { background: #bbcefb; border-radius: 3px; padding: 0 3px; }\n",
       "    .entity-QUANTITY { background: #e5ffbb; border-radius: 3px; padding: 0 3px; }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "import scipy\n",
    "from nltk import ne_chunk\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout,widgets\n",
    "from IPython.display import display, HTML, Markdown,clear_output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "  \n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Custom CSS for highlighting entities\n",
    "def apply_custom_styles():\n",
    "    display(HTML(\"\"\"\n",
    "    <style>\n",
    "    .entity-PERSON { background: #ffccd5; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-ORG { background: #c3eeff; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-GPE { background: #c1ffba; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-LOC { background: #d6ffba; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-MONEY { background: #ffe5a8; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-TIME { background: #e5ceff; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-DATE { background: #cecdff; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-PERCENT { background: #bbffee; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-CARDINAL { background: #eeedff; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-TICKER { background: #ffbadd; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-COMPANY { background: #c3eeff; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-PRODUCT { background: #bbcefb; border-radius: 3px; padding: 0 3px; }\n",
    "    .entity-QUANTITY { background: #e5ffbb; border-radius: 3px; padding: 0 3px; }\n",
    "    </style>\n",
    "    \"\"\"))\n",
    "\n",
    "apply_custom_styles()\n",
    "\n",
    "# Sample financial texts to use throughout the notebook\n",
    "sample_texts = {\n",
    "    \"earnings_report\": \"Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estimates by $0.15. Revenue was $97.3 billion, up 9% year-over-year. CEO Tim Cook mentioned strong iPhone sales in emerging markets.\",\n",
    "    \"financial_news\": \"Microsoft (MSFT) stock rose 3.2% to $245.67 after announcing plans to invest $10 billion in OpenAI on January 15, 2023. The tech giant expects the partnership to generate significant revenue by 2025.\",\n",
    "    \"sec_filing\": \"According to the 10-K filing, Tesla Inc. (TSLA) increased R&D spending to $3.1 billion in 2022, representing 5.7% of the total revenue. The company plans to launch new products in Q3 2023.\",\n",
    "    \"market_analysis\": \"The S&P 500 fell 1.2% yesterday, with energy stocks like Exxon Mobil (XOM) and Chevron (CVX) dropping over 3%. The Federal Reserve's decision to maintain interest rates at 5.25% influenced market sentiment.\",\n",
    "    \"complex_example\": \"In Q2 2023, Amazon.com Inc. (AMZN) acquired Zoox for $1.2 billion while reporting earnings of $2.63 per share. The deal closed on August 12, 2023, when AMZN was trading at $135.28.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ea7217-8a66-4fd1-9408-80eba7820657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be77845fb494caca6d2a85c0be1632d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Example:', layout=Layout(width='50%'), options=('earnings_report', 'financial_news', 'se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c17ec24fa43449db137825acfe4a322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estimates by $0.15. Revenue…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520a700a381c4c64802f70c5b637e09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estim…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    \"\"\"Extract named entities using spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Standard spaCy entities\n",
    "    entities = {ent.text: ent.label_ for ent in doc.ents}\n",
    "    \n",
    "    # Additional financial entity extraction\n",
    "    for token in doc:\n",
    "        # Find potential tickers (uppercase words in parentheses)\n",
    "        if token.text == \"(\" and token.i + 1 < len(doc) and token.i + 2 < len(doc):\n",
    "            next_token = doc[token.i + 1]\n",
    "            next_next_token = doc[token.i + 2]\n",
    "            \n",
    "            if next_token.is_upper and next_next_token.text == \")\":\n",
    "                if next_token.text not in entities:\n",
    "                    entities[f\"({next_token.text})\"] = \"TICKER\"\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def extract_entities_nltk(text):\n",
    "    \"\"\"Extract named entities using NLTK\"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    named_entities = nltk.ne_chunk(pos_tags)\n",
    "    \n",
    "    entities = {}\n",
    "    \n",
    "    # Process named entities\n",
    "    for chunk in named_entities:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entity = \" \".join([token for token, pos in chunk.leaves()])\n",
    "            entities[entity] = chunk.label()\n",
    "    \n",
    "    # Apply additional rules for financial entities\n",
    "    for i, (token, pos) in enumerate(pos_tags):\n",
    "        # Find monetary values\n",
    "        if token.startswith('$') and i + 1 < len(pos_tags):\n",
    "            next_token = pos_tags[i + 1][0]\n",
    "            if next_token.lower() in ['million', 'billion', 'trillion', 'm', 'b', 't']:\n",
    "                entities[f\"{token} {next_token}\"] = \"MONEY\"\n",
    "            else:\n",
    "                entities[token] = \"MONEY\"\n",
    "        \n",
    "        # Find percentages\n",
    "        if token.endswith('%') and pos == 'CD':\n",
    "            entities[token] = \"PERCENT\"\n",
    "        \n",
    "        # Find potential tickers\n",
    "        if token == \"(\" and i + 1 < len(pos_tags) and i + 2 < len(pos_tags):\n",
    "            next_token = pos_tags[i + 1][0]\n",
    "            next_pos = pos_tags[i + 1][1]\n",
    "            next_next_token = pos_tags[i + 2][0]\n",
    "            \n",
    "            if next_token.isupper() and next_next_token == \")\":\n",
    "                entities[f\"({next_token})\"] = \"TICKER\"\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def extract_entities_regex(text):\n",
    "    \"\"\"Extract entities using our custom regex approach\"\"\"\n",
    "    entities = {}\n",
    "    \n",
    "    # Extract ticker symbols\n",
    "    ticker_pattern = r'\\(([A-Z]{1,5})\\)'\n",
    "    for match in re.finditer(ticker_pattern, text):\n",
    "        ticker = match.group(0)  # Get the full match with parentheses\n",
    "        entities[ticker] = \"TICKER\"\n",
    "    \n",
    "    # Extract monetary values\n",
    "    money_pattern = r'\\$\\d+(?:\\.\\d+)?(?:\\s?(?:billion|million|thousand|B|M|K))?'\n",
    "    for match in re.finditer(money_pattern, text):\n",
    "        entities[match.group(0)] = \"MONEY\"\n",
    "    \n",
    "    # Extract percentages\n",
    "    percent_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    for match in re.finditer(percent_pattern, text):\n",
    "        entities[match.group(0)] = \"PERCENT\"\n",
    "    \n",
    "    # Extract dates\n",
    "    date_pattern = r'(?:Q[1-4]\\s?(?:20)?\\d{2})|(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2},?\\s\\d{4}'\n",
    "    for match in re.finditer(date_pattern, text):\n",
    "        entities[match.group(0)] = \"DATE\"\n",
    "    \n",
    "    # Extract company names\n",
    "    company_pattern = r'([A-Z][a-zA-Z\\.\\s]+(?:Inc\\.|Corp\\.|Ltd\\.|LLC|Group|Company))'\n",
    "    for match in re.finditer(company_pattern, text):\n",
    "        entities[match.group(0).strip()] = \"COMPANY\"\n",
    "    \n",
    "    # Extract person names\n",
    "    person_pattern = r'(?:Mr\\.|Mrs\\.|Ms\\.|Dr\\.|CEO|CFO|CTO)\\s([A-Z][a-z]+(?:\\s[A-Z][a-z]+){1,2})'\n",
    "    for match in re.finditer(person_pattern, text):\n",
    "        # Get the person's name including the title\n",
    "        entities[match.group(0).strip()] = \"PERSON\"\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def compare_ner_methods(text):\n",
    "    \"\"\"Compare different NER methods on the same text\"\"\"\n",
    "    # Get entities from each method\n",
    "    spacy_entities = extract_entities_spacy(text)\n",
    "    nltk_entities = extract_entities_nltk(text)\n",
    "    regex_entities = extract_entities_regex(text)\n",
    "    \n",
    "    # Count entities by type for each method\n",
    "    spacy_counts = {}\n",
    "    for entity, label in spacy_entities.items():\n",
    "        spacy_counts[label] = spacy_counts.get(label, 0) + 1\n",
    "    \n",
    "    nltk_counts = {}\n",
    "    for entity, label in nltk_entities.items():\n",
    "        nltk_counts[label] = nltk_counts.get(label, 0) + 1\n",
    "    \n",
    "    regex_counts = {}\n",
    "    for entity, label in regex_entities.items():\n",
    "        regex_counts[label] = regex_counts.get(label, 0) + 1\n",
    "    \n",
    "    # Create DataFrames for comparison\n",
    "    spacy_df = pd.DataFrame([(entity, label) for entity, label in spacy_entities.items()], \n",
    "                           columns=[\"Entity\", \"Type\"])\n",
    "    nltk_df = pd.DataFrame([(entity, label) for entity, label in nltk_entities.items()], \n",
    "                          columns=[\"Entity\", \"Type\"])\n",
    "    regex_df = pd.DataFrame([(entity, label) for entity, label in regex_entities.items()], \n",
    "                           columns=[\"Entity\", \"Type\"])\n",
    "    \n",
    "    # Display original text\n",
    "    display(HTML(f\"<h3>Original Text:</h3><p>{text}</p>\"))\n",
    "    \n",
    "    # Display entity counts\n",
    "    display(HTML(\"<h3>Entity Counts by Method:</h3>\"))\n",
    "    \n",
    "    # Create comparison table\n",
    "    all_labels = sorted(list(set(list(spacy_counts.keys()) + list(nltk_counts.keys()) + list(regex_counts.keys()))))\n",
    "    comparison_data = []\n",
    "    \n",
    "    for label in all_labels:\n",
    "        comparison_data.append({\n",
    "            \"Entity Type\": label,\n",
    "            \"spaCy\": spacy_counts.get(label, 0),\n",
    "            \"NLTK\": nltk_counts.get(label, 0),\n",
    "            \"Regex\": regex_counts.get(label, 0)\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Create bar chart comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    bar_width = 0.25\n",
    "    x = np.arange(len(all_labels))\n",
    "    \n",
    "    plt.bar(x - bar_width, [spacy_counts.get(label, 0) for label in all_labels], \n",
    "            width=bar_width, label='spaCy', color='skyblue')\n",
    "    plt.bar(x, [nltk_counts.get(label, 0) for label in all_labels], \n",
    "            width=bar_width, label='NLTK', color='lightgreen')\n",
    "    plt.bar(x + bar_width, [regex_counts.get(label, 0) for label in all_labels], \n",
    "            width=bar_width, label='Regex', color='salmon')\n",
    "    \n",
    "    plt.xlabel('Entity Types')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Entity Count Comparison by Method')\n",
    "    plt.xticks(x, all_labels, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display entities found by each method\n",
    "    display(HTML(\"<h3>Entities Found by Method:</h3>\"))\n",
    "    \n",
    "    # Highlight entities in text for each method\n",
    "    spacy_highlighted = text\n",
    "    for entity, label in sorted(spacy_entities.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "        spacy_highlighted = spacy_highlighted.replace(entity, f'<span class=\"entity-{label}\">{entity}</span>')\n",
    "    \n",
    "    nltk_highlighted = text\n",
    "    for entity, label in sorted(nltk_entities.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "        nltk_highlighted = nltk_highlighted.replace(entity, f'<span class=\"entity-{label}\">{entity}</span>')\n",
    "    \n",
    "    regex_highlighted = text\n",
    "    for entity, label in sorted(regex_entities.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "        regex_highlighted = regex_highlighted.replace(entity, f'<span class=\"entity-{label}\">{entity}</span>')\n",
    "    \n",
    "    # Display highlighted text\n",
    "    display(HTML(\"<h4>spaCy Entities:</h4>\"))\n",
    "    display(HTML(f\"<p>{spacy_highlighted}</p>\"))\n",
    "    \n",
    "    display(HTML(\"<h4>NLTK Entities:</h4>\"))\n",
    "    display(HTML(f\"<p>{nltk_highlighted}</p>\"))\n",
    "    \n",
    "    display(HTML(\"<h4>Regex Entities:</h4>\"))\n",
    "    display(HTML(f\"<p>{regex_highlighted}</p>\"))\n",
    "    \n",
    "    # Create tables of entities\n",
    "    display(HTML(\"<h4>spaCy Entities:</h4>\"))\n",
    "    display(spacy_df)\n",
    "    \n",
    "    display(HTML(\"<h4>NLTK Entities:</h4>\"))\n",
    "    display(nltk_df)\n",
    "    \n",
    "    display(HTML(\"<h4>Regex Entities:</h4>\"))\n",
    "    display(regex_df)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    display(HTML(\"<h3>Performance Analysis:</h3>\"))\n",
    "    \n",
    "    # Measure time performance\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    extract_entities_spacy(text)\n",
    "    spacy_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    extract_entities_nltk(text)\n",
    "    nltk_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    extract_entities_regex(text)\n",
    "    regex_time = time.time() - start_time\n",
    "    \n",
    "    # Display timing results\n",
    "    timing_data = {\n",
    "        \"Method\": [\"spaCy\", \"NLTK\", \"Regex\"],\n",
    "        \"Processing Time (s)\": [spacy_time, nltk_time, regex_time]\n",
    "    }\n",
    "    timing_df = pd.DataFrame(timing_data)\n",
    "    display(timing_df)\n",
    "    \n",
    "    # Plot timing comparison\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(timing_df[\"Method\"], timing_df[\"Processing Time (s)\"], color=['skyblue', 'lightgreen', 'salmon'])\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Processing Time (s)\")\n",
    "    plt.title(\"Processing Time Comparison\")\n",
    "    \n",
    "    # Add timing labels on bars\n",
    "    for i, time_val in enumerate(timing_df[\"Processing Time (s)\"]):\n",
    "        plt.text(i, time_val + 0.0001, f\"{time_val:.6f}s\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display method comparison and recommendations\n",
    "    display(HTML(\"\"\"\n",
    "    <h3>Method Comparison:</h3>\n",
    "    <table style=\"width:100%; border-collapse: collapse;\">\n",
    "        <tr>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Method</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Strengths</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Weaknesses</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Best For</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\"><b>spaCy</b></td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Pre-trained on diverse data<br>\n",
    "                • Contextual understanding<br>\n",
    "                • Handles complex language<br>\n",
    "                • Supports custom training\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Not specialized for financial text<br>\n",
    "                • May miss domain-specific entities<br>\n",
    "                • More resource-intensive\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • General-purpose NER<br>\n",
    "                • Projects requiring context<br>\n",
    "                • Production environments\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\"><b>NLTK</b></td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Well-established library<br>\n",
    "                • Good for academic use<br>\n",
    "                • Flexible rule creation\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Less contextual understanding<br>\n",
    "                • Limited entity types<br>\n",
    "                • Requires more custom rules\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Academic research<br>\n",
    "                • Basic NER tasks<br>\n",
    "                • Educational purposes\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\"><b>Regex</b></td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Highly customizable<br>\n",
    "                • Domain-specific patterns<br>\n",
    "                • Fastest performance<br>\n",
    "                • No external dependencies\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • No contextual understanding<br>\n",
    "                • Prone to false positives<br>\n",
    "                • Requires manual pattern creation<br>\n",
    "                • Hard to maintain as patterns grow\n",
    "            </td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\n",
    "                • Financial-specific entities<br>\n",
    "                • Simple document processing<br>\n",
    "                • Pattern-based extraction\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    \n",
    "    <h3>Recommendations for Financial NER:</h3>\n",
    "    <ol>\n",
    "        <li><b>Hybrid Approach:</b> Combine spaCy for general entities with custom regex patterns for financial-specific entities</li>\n",
    "        <li><b>Fine-tuned Models:</b> Consider fine-tuning spaCy on financial documents for better domain-specific performance</li>\n",
    "        <li><b>Entity Verification:</b> Implement post-processing to validate extracted entities against financial knowledge bases</li>\n",
    "        <li><b>Context Analysis:</b> Use surrounding text to disambiguate entities with multiple meanings</li>\n",
    "    </ol>\n",
    "    \"\"\"))\n",
    "\n",
    "# Create interactive comparison\n",
    "def interactive_ner_comparison(text):\n",
    "    compare_ner_methods(text)\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value=sample_texts[\"earnings_report\"],\n",
    "    placeholder='Enter financial text...',\n",
    "    description='Text:',\n",
    "    layout=Layout(width='90%', height='100px')\n",
    ")\n",
    "\n",
    "examples = widgets.Dropdown(\n",
    "    options=list(sample_texts.keys()),\n",
    "    value='earnings_report',\n",
    "    description='Example:',\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Function to update text when dropdown changes\n",
    "def update_text(change):\n",
    "    text_input.value = sample_texts[change['new']]\n",
    "\n",
    "# Register callback for dropdown\n",
    "examples.observe(update_text, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(examples)\n",
    "display(text_input)\n",
    "\n",
    "# Use interact for the comparison\n",
    "interact(interactive_ner_comparison, text=text_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daaa90a-e226-4746-bcca-090a4380b77d",
   "metadata": {},
   "source": [
    "<a id='visualization'></a>\n",
    "## 5. Data Flow Visualization\n",
    "\n",
    "Let's visualize how text flows through the NER pipeline, from raw input to structured entities. This will help us understand each processing stage and how different components interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c863d33f-c6db-49f4-9a7d-071410908607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c76078abf044753af86ada580731561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Example:', layout=Layout(width='50%'), options=('earnings_report', 'financial_news', 'se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b819508d9e24511be465faa1ac50107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estimates by $0.15. Revenue…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436d552df029493b8e3033952f189a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estim…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_ner_pipeline(text):\n",
    "    \"\"\"\n",
    "    Visualize the NER pipeline and data flow for financial text analysis\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize pipeline stages\n",
    "    stages = [\n",
    "        \"Raw Text Input\",\n",
    "        \"Text Preprocessing\",\n",
    "        \"Tokenization\",\n",
    "        \"Entity Recognition\",\n",
    "        \"Entity Classification\",\n",
    "        \"Structured Output\"\n",
    "    ]\n",
    "    \n",
    "    # Step 2: Process text through each stage\n",
    "    # Raw text is the input\n",
    "    raw_text = text\n",
    "    \n",
    "    # Preprocessing (lowercase everything except potential entities, remove extra spaces)\n",
    "    def preprocess_text(text):\n",
    "        # Keep uppercase for potential entities\n",
    "        processed = []\n",
    "        for token in text.split():\n",
    "            # Don't lowercase potential tickers, companies, etc.\n",
    "            if re.match(r'\\([A-Z]+\\)', token) or re.match(r'^[A-Z][a-z]+$', token) or token.startswith('$'):\n",
    "                processed.append(token)\n",
    "            else:\n",
    "                processed.append(token)\n",
    "        return ' '.join(processed)\n",
    "    \n",
    "    preprocessed_text = preprocess_text(raw_text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(preprocessed_text)\n",
    "    \n",
    "    # Entity Recognition (using spaCy)\n",
    "    doc = nlp(preprocessed_text)\n",
    "    \n",
    "    # Get entities from spaCy\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # Add custom financial entities\n",
    "    custom_entities = []\n",
    "    \n",
    "    # Extract tickers\n",
    "    ticker_pattern = r'\\(([A-Z]{1,5})\\)'\n",
    "    for match in re.finditer(ticker_pattern, preprocessed_text):\n",
    "        ticker = match.group(0)  # Get the full match with parentheses\n",
    "        if not any(ticker == e[0] for e in entities + custom_entities):\n",
    "            custom_entities.append((ticker, \"TICKER\"))\n",
    "    \n",
    "    # Extract monetary values\n",
    "    money_pattern = r'\\$\\d+(?:\\.\\d+)?(?:\\s?(?:billion|million|thousand|B|M|K))?'\n",
    "    for match in re.finditer(money_pattern, preprocessed_text):\n",
    "        money = match.group(0)\n",
    "        if not any(money == e[0] for e in entities + custom_entities):\n",
    "            custom_entities.append((money, \"MONEY\"))\n",
    "    \n",
    "    # Extract percentages\n",
    "    percent_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    for match in re.finditer(percent_pattern, preprocessed_text):\n",
    "        percent = match.group(0)\n",
    "        if not any(percent == e[0] for e in entities + custom_entities):\n",
    "            custom_entities.append((percent, \"PERCENT\"))\n",
    "    \n",
    "    # Combine spaCy and custom entities\n",
    "    all_entities = entities + custom_entities\n",
    "    \n",
    "    # Entity Classification (organize by type)\n",
    "    entity_by_type = {}\n",
    "    for entity, label in all_entities:\n",
    "        if label not in entity_by_type:\n",
    "            entity_by_type[label] = []\n",
    "        entity_by_type[label].append(entity)\n",
    "    \n",
    "    # Create structured output (JSON-like)\n",
    "    structured_output = {\n",
    "        \"text\": raw_text,\n",
    "        \"entities\": entity_by_type\n",
    "    }\n",
    "    \n",
    "    # Step 3: Visualize the pipeline\n",
    "    display(HTML(\"<h3>NER Pipeline Visualization</h3>\"))\n",
    "    \n",
    "    # Create pipeline diagram\n",
    "    import networkx as nx\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes for stages\n",
    "    for i, stage in enumerate(stages):\n",
    "        G.add_node(stage, pos=(i, 0))\n",
    "    \n",
    "    # Add edges between stages\n",
    "    for i in range(len(stages) - 1):\n",
    "        G.add_edge(stages[i], stages[i + 1])\n",
    "    \n",
    "    plt.figure(figsize=(14, 3))\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', \n",
    "            node_size=3000, font_size=10, font_weight='bold', \n",
    "            arrows=True, arrowsize=20)\n",
    "    plt.title(\"NER Pipeline Flow\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize content at each stage\n",
    "    display(HTML(\"<h3>Data Flow Through Pipeline Stages</h3>\"))\n",
    "    \n",
    "    # Stage 1: Raw Text\n",
    "    display(HTML(f\"<h4>Stage 1: {stages[0]}</h4>\"))\n",
    "    display(HTML(f\"<p>{raw_text}</p>\"))\n",
    "    \n",
    "    # Stage 2: Preprocessing\n",
    "    display(HTML(f\"<h4>Stage 2: {stages[1]}</h4>\"))\n",
    "    display(HTML(f\"<p>{preprocessed_text}</p>\"))\n",
    "    \n",
    "    # Stage 3: Tokenization\n",
    "    display(HTML(f\"<h4>Stage 3: {stages[2]}</h4>\"))\n",
    "    tokenized_html = \"<div style='line-height: 2.5;'>\"\n",
    "    for token in tokens:\n",
    "        tokenized_html += f'<span style=\"border: 1px solid #ccc; border-radius: 3px; padding: 3px; margin: 2px;\">{token}</span> '\n",
    "    tokenized_html += \"</div>\"\n",
    "    display(HTML(tokenized_html))\n",
    "    \n",
    "    # Stage 4: Entity Recognition\n",
    "    display(HTML(f\"<h4>Stage 4: {stages[3]}</h4>\"))\n",
    "    # Create color mapping for entity types\n",
    "    entity_colors = {\n",
    "        \"PERSON\": \"#ffccd5\",\n",
    "        \"ORG\": \"#c3eeff\",\n",
    "        \"GPE\": \"#c1ffba\",\n",
    "        \"LOC\": \"#d6ffba\",\n",
    "        \"MONEY\": \"#ffe5a8\",\n",
    "        \"TIME\": \"#e5ceff\",\n",
    "        \"DATE\": \"#cecdff\",\n",
    "        \"PERCENT\": \"#bbffee\",\n",
    "        \"CARDINAL\": \"#eeedff\",\n",
    "        \"TICKER\": \"#ffbadd\",\n",
    "        \"PRODUCT\": \"#bbcefb\",\n",
    "        \"QUANTITY\": \"#e5ffbb\"\n",
    "    }\n",
    "    \n",
    "    # Highlight entities in text\n",
    "    entity_recognition_html = raw_text\n",
    "    for entity, label in sorted(all_entities, key=lambda x: len(x[0]), reverse=True):\n",
    "        color = entity_colors.get(label, \"#cccccc\")\n",
    "        entity_recognition_html = entity_recognition_html.replace(\n",
    "            entity, \n",
    "            f'<span style=\"background-color: {color}; border-radius: 3px; padding: 2px;\">{entity}</span>'\n",
    "        )\n",
    "    \n",
    "    display(HTML(f\"<p>{entity_recognition_html}</p>\"))\n",
    "    \n",
    "    # Stage 5: Entity Classification\n",
    "    display(HTML(f\"<h4>Stage 5: {stages[4]}</h4>\"))\n",
    "    \n",
    "    # Create a table to show entity classification\n",
    "    classification_html = \"\"\"\n",
    "    <table style=\"width: 80%; border-collapse: collapse;\">\n",
    "      <tr>\n",
    "        <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Entity Type</th>\n",
    "        <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Entities</th>\n",
    "      </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    for label, entities in entity_by_type.items():\n",
    "        color = entity_colors.get(label, \"#cccccc\")\n",
    "        entities_html = \", \".join([\n",
    "            f'<span style=\"background-color: {color}; border-radius: 3px; padding: 2px;\">{entity}</span>'\n",
    "            for entity in entities\n",
    "        ])\n",
    "        \n",
    "        classification_html += f\"\"\"\n",
    "        <tr>\n",
    "          <td style=\"border: 1px solid #ddd; padding: 8px;\">{label}</td>\n",
    "          <td style=\"border: 1px solid #ddd; padding: 8px;\">{entities_html}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    classification_html += \"</table>\"\n",
    "    display(HTML(classification_html))\n",
    "    \n",
    "    # Stage 6: Structured Output\n",
    "    display(HTML(f\"<h4>Stage 6: {stages[5]}</h4>\"))\n",
    "    \n",
    "    # Display structured output\n",
    "    from IPython.display import JSON\n",
    "    display(JSON(structured_output))\n",
    "    \n",
    "    # Visualize entity distribution\n",
    "    display(HTML(\"<h3>Entity Distribution</h3>\"))\n",
    "    \n",
    "    # Create a bar chart of entity counts by type\n",
    "    entity_counts = {label: len(entities) for label, entities in entity_by_type.items()}\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(entity_counts.keys(), entity_counts.values(), color=[entity_colors.get(label, \"#cccccc\") for label in entity_counts.keys()])\n",
    "    plt.title(\"Entity Counts by Type\")\n",
    "    plt.xlabel(\"Entity Type\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1, str(int(height)), \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a Sankey diagram to show entity flow\n",
    "    try:\n",
    "        import plotly.graph_objects as go\n",
    "        from plotly.subplots import make_subplots\n",
    "        \n",
    "        # Set up node labels and values for Sankey diagram\n",
    "        label = [\"Raw Text\"]\n",
    "        for stage in stages[1:]:\n",
    "            label.append(stage)\n",
    "        \n",
    "        for entity_type, entities in entity_by_type.items():\n",
    "            for entity in entities:\n",
    "                label.append(f\"{entity_type}: {entity}\")\n",
    "        \n",
    "        # Create source, target pairs\n",
    "        source = []\n",
    "        target = []\n",
    "        value = []\n",
    "        \n",
    "        # Connect stages\n",
    "        for i in range(len(stages) - 1):\n",
    "            source.append(i)\n",
    "            target.append(i + 1)\n",
    "            value.append(10)  # Constant width for main pipeline flow\n",
    "        \n",
    "        # Connect entities to Entity Classification\n",
    "        entity_start_idx = len(stages)\n",
    "        for entity_type, entities in entity_by_type.items():\n",
    "            for entity in entities:\n",
    "                # Connect Entity Recognition to this entity\n",
    "                source.append(3)  # Entity Recognition stage\n",
    "                target.append(entity_start_idx)\n",
    "                value.append(1)  # Entity width\n",
    "                \n",
    "                # Connect this entity to Entity Classification\n",
    "                source.append(entity_start_idx)\n",
    "                target.append(4)  # Entity Classification stage\n",
    "                value.append(1)  # Entity width\n",
    "                \n",
    "                entity_start_idx += 1\n",
    "        \n",
    "        # Create Sankey diagram\n",
    "        fig = go.Figure(data=[go.Sankey(\n",
    "            node=dict(\n",
    "                pad=15,\n",
    "                thickness=20,\n",
    "                line=dict(color=\"black\", width=0.5),\n",
    "                label=label\n",
    "            ),\n",
    "            link=dict(\n",
    "                source=source,\n",
    "                target=target,\n",
    "                value=value\n",
    "            )\n",
    "        )])\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"NER Data Flow\",\n",
    "            font_size=10,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        display(HTML(f\"<p>Sankey diagram could not be displayed: {e}</p>\"))\n",
    "        # Fallback visualization\n",
    "        display(HTML(\"<p>Simple data flow visualization:</p>\"))\n",
    "        # Add a simple alternative visualization here\n",
    "\n",
    "# Create interactive widgets\n",
    "examples = widgets.Dropdown(\n",
    "    options=list(sample_texts.keys()),\n",
    "    value='earnings_report',\n",
    "    description='Example:',\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "text_input = widgets.Textarea(\n",
    "    value=sample_texts['earnings_report'],\n",
    "    placeholder='Enter financial text...',\n",
    "    description='Text:',\n",
    "    layout=Layout(width='90%', height='100px')\n",
    ")\n",
    "\n",
    "# Function to update text when dropdown changes\n",
    "def update_text(change):\n",
    "    text_input.value = sample_texts[change['new']]\n",
    "\n",
    "# Register callback for dropdown\n",
    "examples.observe(update_text, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(examples)\n",
    "display(text_input)\n",
    "\n",
    "# Use interact for the visualization\n",
    "interact(visualize_ner_pipeline, text=text_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21173c-7258-4333-9dcc-bbba445c7c1f",
   "metadata": {},
   "source": [
    "<a id='user-interaction'></a>\n",
    "## 6. User Interaction & Visualization\n",
    "\n",
    "This section focuses on creating interactive visualizations that allow users to explore named entities in financial documents. We'll implement real-time entity highlighting, entity relationship exploration, and parameter adjustments to enhance the analysis experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f2e82c-51c9-444f-a7ae-6ebdc1d5e0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711918e42d62466fac3182dbc6ae4c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Example:', layout=Layout(width='50%'), options=('earnings_report', 'financial_news', 'se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed690a3b77264c9c838e27a2310552b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Apple Inc. (AAPL) reported Q2 earnings of $1.52 per share, beating estimates by $0.15. Revenue…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e689dd42fb46248727604c566591af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), selected_index=0, titles=('Entity Highlighting', 'Entity Relationships'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_entity_highlighter(text):\n",
    "    \"\"\"\n",
    "    Create an interactive entity highlighter for financial text\n",
    "    \"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract entities using multiple methods\n",
    "    spacy_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # Add custom financial entities\n",
    "    financial_entities = []\n",
    "    \n",
    "    # Extract ticker symbols\n",
    "    ticker_pattern = r'\\(([A-Z]{1,5})\\)'\n",
    "    for match in re.finditer(ticker_pattern, text):\n",
    "        ticker = match.group(0)  # Full match with parentheses\n",
    "        financial_entities.append((ticker, 'TICKER'))\n",
    "    \n",
    "    # Extract monetary values\n",
    "    money_pattern = r'\\$\\d+(?:\\.\\d+)?(?:\\s?(?:billion|million|thousand|B|M|K))?'\n",
    "    for match in re.finditer(money_pattern, text):\n",
    "        financial_entities.append((match.group(0), 'MONEY'))\n",
    "    \n",
    "    # Extract percentages\n",
    "    percent_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    for match in re.finditer(percent_pattern, text):\n",
    "        financial_entities.append((match.group(0), 'PERCENT'))\n",
    "    \n",
    "    # Combine all entities and remove duplicates\n",
    "    all_entities = []\n",
    "    seen_entities = set()\n",
    "    \n",
    "    for entity, label in spacy_entities + financial_entities:\n",
    "        if entity not in seen_entities:\n",
    "            all_entities.append((entity, label))\n",
    "            seen_entities.add(entity)\n",
    "    \n",
    "    # Group entities by type\n",
    "    entity_types = sorted(list(set(label for _, label in all_entities)))\n",
    "    \n",
    "    # Create checkboxes for each entity type\n",
    "    type_checkboxes = [widgets.Checkbox(\n",
    "        value=True,\n",
    "        description=f\"{entity_type}\",\n",
    "        disabled=False\n",
    "    ) for entity_type in entity_types]\n",
    "    \n",
    "    # Create a checkbox for showing all entities\n",
    "    all_checkbox = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Show All',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "    )\n",
    "    \n",
    "    # Create a layout for the checkboxes\n",
    "    checkbox_layout = widgets.Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row wrap',\n",
    "        align_items='stretch',\n",
    "        width='90%'\n",
    "    )\n",
    "    \n",
    "    checkbox_container = widgets.Box(\n",
    "        children=[all_checkbox] + type_checkboxes,\n",
    "        layout=checkbox_layout\n",
    "    )\n",
    "    \n",
    "    # Create a function to update the highlighted text\n",
    "    def update_highlighted_text(*args):\n",
    "        # If \"Show All\" is checked, check all entity types\n",
    "        if all_checkbox.value:\n",
    "            for checkbox in type_checkboxes:\n",
    "                checkbox.value = True\n",
    "        \n",
    "        # Get selected entity types\n",
    "        selected_types = [entity_types[i] for i, checkbox in enumerate(type_checkboxes) if checkbox.value]\n",
    "        \n",
    "        # Filter entities by selected types\n",
    "        filtered_entities = [entity for entity, label in all_entities if label in selected_types]\n",
    "        \n",
    "        # Create highlighted HTML\n",
    "        highlighted_html = text\n",
    "        \n",
    "        # Sort entities by length in descending order to avoid replacement issues\n",
    "        for entity, label in sorted(all_entities, key=lambda x: len(x[0]), reverse=True):\n",
    "            if label in selected_types:\n",
    "                highlighted_html = highlighted_html.replace(\n",
    "                    entity, \n",
    "                    f'<span class=\"entity-{label}\">{entity}</span>'\n",
    "                )\n",
    "        \n",
    "        # Display highlighted text\n",
    "        display(HTML(\"<h3>Highlighted Entities:</h3>\"))\n",
    "        display(HTML(f\"<p>{highlighted_html}</p>\"))\n",
    "        \n",
    "        # Create entity counts table\n",
    "        entity_counts = {}\n",
    "        for entity, label in all_entities:\n",
    "            if label in selected_types:\n",
    "                entity_counts[label] = entity_counts.get(label, 0) + 1\n",
    "        \n",
    "        display(HTML(\"<h3>Entity Counts:</h3>\"))\n",
    "        if entity_counts:\n",
    "            counts_html = \"\"\"\n",
    "            <table style=\"width:50%; border-collapse: collapse;\">\n",
    "              <tr>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Entity Type</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px; text-align: left;\">Count</th>\n",
    "              </tr>\n",
    "            \"\"\"\n",
    "            \n",
    "            for label, count in entity_counts.items():\n",
    "                counts_html += f\"\"\"\n",
    "                <tr>\n",
    "                  <td style=\"border: 1px solid #ddd; padding: 8px;\">{label}</td>\n",
    "                  <td style=\"border: 1px solid #ddd; padding: 8px;\">{count}</td>\n",
    "                </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            counts_html += \"</table>\"\n",
    "            display(HTML(counts_html))\n",
    "            \n",
    "            # Create bar chart of entity counts\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.bar(entity_counts.keys(), entity_counts.values())\n",
    "            plt.title(\"Entity Counts by Type\")\n",
    "            plt.xlabel(\"Entity Type\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            for i, (label, count) in enumerate(entity_counts.items()):\n",
    "                plt.text(i, count + 0.1, str(count), ha='center')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            display(HTML(\"<p>No entities selected.</p>\"))\n",
    "    \n",
    "    # Register callback for all checkboxes\n",
    "    all_checkbox.observe(update_highlighted_text, names='value')\n",
    "    for checkbox in type_checkboxes:\n",
    "        checkbox.observe(update_highlighted_text, names='value')\n",
    "    \n",
    "    # Display widgets\n",
    "    display(HTML(\"<h3>Select Entity Types to Highlight:</h3>\"))\n",
    "    display(checkbox_container)\n",
    "    \n",
    "    # Initialize display\n",
    "    update_highlighted_text()\n",
    "    \n",
    "    # Return the widgets for further use\n",
    "    return {\n",
    "        'all_checkbox': all_checkbox,\n",
    "        'type_checkboxes': type_checkboxes,\n",
    "        'entity_types': entity_types\n",
    "    }\n",
    "\n",
    "def visualize_entity_relationships(text):\n",
    "    \"\"\"\n",
    "    Visualize relationships between entities in financial text\n",
    "    \"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract entities and their positions\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            'text': ent.text,\n",
    "            'label': ent.label_,\n",
    "            'start': ent.start_char,\n",
    "            'end': ent.end_char\n",
    "        })\n",
    "    \n",
    "    # Add custom financial entities\n",
    "    # Extract ticker symbols\n",
    "    ticker_pattern = r'\\(([A-Z]{1,5})\\)'\n",
    "    for match in re.finditer(ticker_pattern, text):\n",
    "        entities.append({\n",
    "            'text': match.group(0),\n",
    "            'label': 'TICKER',\n",
    "            'start': match.start(),\n",
    "            'end': match.end()\n",
    "        })\n",
    "    \n",
    "    # Extract monetary values\n",
    "    money_pattern = r'\\$\\d+(?:\\.\\d+)?(?:\\s?(?:billion|million|thousand|B|M|K))?'\n",
    "    for match in re.finditer(money_pattern, text):\n",
    "        entities.append({\n",
    "            'text': match.group(0),\n",
    "            'label': 'MONEY',\n",
    "            'start': match.start(),\n",
    "            'end': match.end()\n",
    "        })\n",
    "    \n",
    "    # Extract percentages\n",
    "    percent_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    for match in re.finditer(percent_pattern, text):\n",
    "        entities.append({\n",
    "            'text': match.group(0),\n",
    "            'label': 'PERCENT',\n",
    "            'start': match.start(),\n",
    "            'end': match.end()\n",
    "        })\n",
    "    \n",
    "    # Remove duplicate entities\n",
    "    unique_entities = []\n",
    "    seen_spans = set()\n",
    "    \n",
    "    for entity in entities:\n",
    "        span = (entity['start'], entity['end'])\n",
    "        if span not in seen_spans:\n",
    "            unique_entities.append(entity)\n",
    "            seen_spans.add(span)\n",
    "    \n",
    "    # Sort entities by position\n",
    "    unique_entities.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Create dependency visualization\n",
    "    display(HTML(\"<h3>Entity Relationships:</h3>\"))\n",
    "    \n",
    "    # Calculate proximity between entities\n",
    "    relationships = []\n",
    "    \n",
    "    for i, entity1 in enumerate(unique_entities):\n",
    "        for j, entity2 in enumerate(unique_entities):\n",
    "            if i < j:  # Only consider each pair once\n",
    "                # Calculate token distance\n",
    "                distance = abs(entity1['start'] - entity2['start'])\n",
    "                \n",
    "                # Entities within certain character distance are considered related\n",
    "                if distance < 50:  # Adjustable threshold\n",
    "                    relationships.append({\n",
    "                        'source': entity1['text'],\n",
    "                        'source_type': entity1['label'],\n",
    "                        'target': entity2['text'],\n",
    "                        'target_type': entity2['label'],\n",
    "                        'weight': 1 / (distance + 1)  # Weight inversely proportional to distance\n",
    "                    })\n",
    "    \n",
    "    # Create a network graph of entity relationships\n",
    "    import networkx as nx\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for each entity\n",
    "    for entity in unique_entities:\n",
    "        G.add_node(entity['text'], type=entity['label'])\n",
    "    \n",
    "    # Add edges for relationships\n",
    "    for relation in relationships:\n",
    "        G.add_edge(\n",
    "            relation['source'], \n",
    "            relation['target'], \n",
    "            weight=relation['weight']\n",
    "        )\n",
    "    \n",
    "    # Display the network graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create a color map for entity types\n",
    "    entity_types = list(set(entity['label'] for entity in unique_entities))\n",
    "    color_map = plt.cm.get_cmap('tab10', len(entity_types))\n",
    "    type_to_color = {entity_type: color_map(i) for i, entity_type in enumerate(entity_types)}\n",
    "    \n",
    "    node_colors = [type_to_color[G.nodes[node]['type']] for node in G.nodes()]\n",
    "    \n",
    "    # Create layout\n",
    "    pos = nx.spring_layout(G, k=0.3)\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=700, alpha=0.8)\n",
    "    \n",
    "    # Draw edges with width proportional to weight\n",
    "    edge_weights = [G[u][v]['weight'] * 3 for u, v in G.edges()]\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.3)\n",
    "    \n",
    "    # Draw node labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_family='sans-serif')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, \n",
    "                                 label=entity_type, markersize=10) \n",
    "                      for entity_type, color in type_to_color.items()]\n",
    "    plt.legend(handles=legend_elements, title=\"Entity Types\")\n",
    "    \n",
    "    plt.title(\"Entity Relationship Network\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create an adjacency matrix visualization\n",
    "    if len(unique_entities) > 1:\n",
    "        # Get the adjacency matrix\n",
    "        A = nx.adjacency_matrix(G).todense()\n",
    "        \n",
    "        # Create labels for the matrix\n",
    "        labels = [entity['text'] for entity in unique_entities]\n",
    "        \n",
    "        # Plot the adjacency matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(A, cmap='Blues')\n",
    "        plt.colorbar(label='Connection Strength')\n",
    "        plt.title(\"Entity Adjacency Matrix\")\n",
    "        \n",
    "        # Add labels\n",
    "        plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "        plt.yticks(range(len(labels)), labels)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Create a co-occurrence table\n",
    "    display(HTML(\"<h3>Entity Co-occurrence:</h3>\"))\n",
    "    \n",
    "    if relationships:\n",
    "        # Create a DataFrame of relationships\n",
    "        relationship_df = pd.DataFrame(relationships)\n",
    "        \n",
    "        # Display the table\n",
    "        display(relationship_df)\n",
    "        \n",
    "        # Create a heatmap of entity co-occurrence\n",
    "        pivot_table = pd.crosstab(\n",
    "            relationship_df['source_type'], \n",
    "            relationship_df['target_type']\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(pivot_table, annot=True, cmap='YlGnBu', fmt='d')\n",
    "        plt.title(\"Entity Type Co-occurrence\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        display(HTML(\"<p>No significant entity relationships detected.</p>\"))\n",
    "\n",
    "def create_interactive_document_analyzer():\n",
    "    \"\"\"\n",
    "    Create an interactive document analyzer with real-time entity extraction and visualization\n",
    "    \"\"\"\n",
    "    # Create tabs for different visualizations\n",
    "    tab1 = widgets.Output()  # Entity Highlighting\n",
    "    tab2 = widgets.Output()  # Entity Relationships\n",
    "    \n",
    "    # Create tabs widget\n",
    "    tabs = widgets.Tab(children=[tab1, tab2])\n",
    "    tabs.set_title(0, 'Entity Highlighting')\n",
    "    tabs.set_title(1, 'Entity Relationships')\n",
    "    \n",
    "    # Create text input widget\n",
    "    text_input = widgets.Textarea(\n",
    "        value=sample_texts['earnings_report'],\n",
    "        placeholder='Enter financial text...',\n",
    "        description='Text:',\n",
    "        layout=Layout(width='90%', height='100px')\n",
    "    )\n",
    "    \n",
    "    # Create example dropdown\n",
    "    examples = widgets.Dropdown(\n",
    "        options=list(sample_texts.keys()),\n",
    "        value='earnings_report',\n",
    "        description='Example:',\n",
    "        layout=Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    # Function to update text when dropdown changes\n",
    "    def update_text(change):\n",
    "        text_input.value = sample_texts[change['new']]\n",
    "        update_tabs()\n",
    "    \n",
    "    # Register callback for dropdown\n",
    "    examples.observe(update_text, names='value')\n",
    "    \n",
    "    # Function to update tab content\n",
    "    def update_tabs():\n",
    "        with tab1:\n",
    "            clear_output()\n",
    "            create_entity_highlighter(text_input.value)\n",
    "        \n",
    "        with tab2:\n",
    "            clear_output()\n",
    "            visualize_entity_relationships(text_input.value)\n",
    "    \n",
    "    # Function to handle text changes\n",
    "    def on_text_change(change):\n",
    "        update_tabs()\n",
    "    \n",
    "    # Register callback for text changes\n",
    "    text_input.observe(on_text_change, names='value')\n",
    "    \n",
    "    # Display widgets\n",
    "    display(examples)\n",
    "    display(text_input)\n",
    "    display(tabs)\n",
    "    \n",
    "    # Initialize tabs\n",
    "    update_tabs()\n",
    "\n",
    "# Create the interactive document analyzer\n",
    "create_interactive_document_analyzer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
